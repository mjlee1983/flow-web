head
  meta(content='text/html; charset=UTF-8' http-equiv='content-type')
  style(type='text/css').
    @import url(https://themes.googleusercontent.com/fonts/css?kit=OUdT43qE98k1fLl98sLVVqp2XEQ3ORDOYyBwgvLfuxU);ul.lst-kix_17xl2evmkbjg-0{list-style-type:none}ul.lst-kix_17xl2evmkbjg-3{list-style-type:none}ul.lst-kix_17xl2evmkbjg-4{list-style-type:none}ul.lst-kix_17xl2evmkbjg-1{list-style-type:none}ul.lst-kix_17xl2evmkbjg-2{list-style-type:none}ul.lst-kix_17xl2evmkbjg-7{list-style-type:none}ul.lst-kix_17xl2evmkbjg-8{list-style-type:none}ul.lst-kix_17xl2evmkbjg-5{list-style-type:none}ul.lst-kix_17xl2evmkbjg-6{list-style-type:none}.lst-kix_17xl2evmkbjg-8>li:before{content:"\0025a0   "}.lst-kix_818oaeavfnqw-5>li:before{content:"\0025a0   "}.lst-kix_818oaeavfnqw-4>li:before{content:"\0025cb   "}.lst-kix_818oaeavfnqw-1>li:before{content:"\0025cb   "}.lst-kix_818oaeavfnqw-2>li:before{content:"\0025a0   "}.lst-kix_818oaeavfnqw-3>li:before{content:"\0025cf   "}.lst-kix_h27acp9hc9hw-0>li:before{content:"\0025cf   "}.lst-kix_818oaeavfnqw-8>li:before{content:"\0025a0   "}.lst-kix_h27acp9hc9hw-2>li:before{content:"\0025a0   "}.lst-kix_h27acp9hc9hw-1>li:before{content:"\0025cb   "}.lst-kix_818oaeavfnqw-6>li:before{content:"\0025cf   "}.lst-kix_818oaeavfnqw-7>li:before{content:"\0025cb   "}.lst-kix_h27acp9hc9hw-7>li:before{content:"\0025cb   "}.lst-kix_h27acp9hc9hw-6>li:before{content:"\0025cf   "}.lst-kix_h27acp9hc9hw-8>li:before{content:"\0025a0   "}.lst-kix_h27acp9hc9hw-3>li:before{content:"\0025cf   "}.lst-kix_h27acp9hc9hw-4>li:before{content:"\0025cb   "}.lst-kix_h27acp9hc9hw-5>li:before{content:"\0025a0   "}.lst-kix_818oaeavfnqw-0>li:before{content:"\0025cf   "}.lst-kix_17xl2evmkbjg-0>li:before{content:"\0025cf   "}ul.lst-kix_818oaeavfnqw-0{list-style-type:none}.lst-kix_17xl2evmkbjg-1>li:before{content:"\0025cb   "}ul.lst-kix_818oaeavfnqw-1{list-style-type:none}.lst-kix_17xl2evmkbjg-2>li:before{content:"\0025a0   "}ul.lst-kix_818oaeavfnqw-6{list-style-type:none}ul.lst-kix_818oaeavfnqw-7{list-style-type:none}ul.lst-kix_818oaeavfnqw-8{list-style-type:none}ul.lst-kix_818oaeavfnqw-2{list-style-type:none}ul.lst-kix_818oaeavfnqw-3{list-style-type:none}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}ul.lst-kix_818oaeavfnqw-4{list-style-type:none}ul.lst-kix_818oaeavfnqw-5{list-style-type:none}ul.lst-kix_h27acp9hc9hw-6{list-style-type:none}ul.lst-kix_h27acp9hc9hw-7{list-style-type:none}ul.lst-kix_h27acp9hc9hw-4{list-style-type:none}.lst-kix_17xl2evmkbjg-7>li:before{content:"\0025cb   "}ul.lst-kix_h27acp9hc9hw-5{list-style-type:none}.lst-kix_17xl2evmkbjg-6>li:before{content:"\0025cf   "}ul.lst-kix_h27acp9hc9hw-8{list-style-type:none}.lst-kix_17xl2evmkbjg-4>li:before{content:"\0025cb   "}.lst-kix_17xl2evmkbjg-3>li:before{content:"\0025cf   "}.lst-kix_17xl2evmkbjg-5>li:before{content:"\0025a0   "}ul.lst-kix_h27acp9hc9hw-2{list-style-type:none}ul.lst-kix_h27acp9hc9hw-3{list-style-type:none}ul.lst-kix_h27acp9hc9hw-0{list-style-type:none}ul.lst-kix_h27acp9hc9hw-1{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c1{margin-left:36pt;padding-top:12pt;padding-left:0pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c11{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c5{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:13pt;font-family:"Figtree";font-style:normal}.c6{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Figtree";font-style:normal}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Figtree";font-style:normal}.c8{padding-top:12pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c2{padding-top:14pt;padding-bottom:4pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c3{font-size:13pt;font-family:"Figtree";color:#000000;font-weight:400}.c10{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c9{font-weight:700;font-family:"Figtree"}.c4{font-weight:400;font-family:"Figtree"}.c7{padding:0;margin:0}.title{padding-top:0pt;color:#000000;font-size:21pt;padding-bottom:0pt;font-family:"Trebuchet MS";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:13pt;padding-bottom:10pt;font-family:"Trebuchet MS";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:10pt;color:#000000;font-size:16pt;padding-bottom:0pt;font-family:"Trebuchet MS";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:10pt;color:#000000;font-weight:700;font-size:13pt;padding-bottom:0pt;font-family:"Trebuchet MS";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:8pt;color:#666666;font-weight:700;font-size:12pt;padding-bottom:0pt;font-family:"Trebuchet MS";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:8pt;-webkit-text-decoration-skip:none;color:#666666;text-decoration:underline;font-size:11pt;padding-bottom:0pt;line-height:1.15;page-break-after:avoid;text-decoration-skip-ink:none;font-family:"Trebuchet MS";orphans:2;widows:2;text-align:left}h5{padding-top:8pt;color:#666666;font-size:11pt;padding-bottom:0pt;font-family:"Trebuchet MS";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:8pt;color:#666666;font-size:11pt;padding-bottom:0pt;font-family:"Trebuchet MS";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}
h3.c2(id='h.ttr1036r2kv6')
  span.c3 Applied Research Engineer, Founding Team
p.c8
  span.c9 Flow AI | 
  span.c9 Bay Area, CA (Remote)
  span.c6 &nbsp;| Full-Time
h3.c2(id='h.8vigvxn6k4bd')
  span.c5 About Flow AI
p.c8
  span.c4
    | At Flow AI, we&apos;re solving one of the most significant and costly problems in the generative AI space:
  span.c4 reliability
  span.c0
    | . Current AI-assisted development tools are powerful but fundamentally unreliable, suffering from hallucinations and logical errors that prevent their use in mission-critical applications. We are a small, deeply technical team of inventors and builders on a mission to create a new foundation for AI-native software development, one built on precision, predictability, and trust. We are backed by a clear vision and a proprietary architecture that moves beyond the limitations of existing approaches.
h3.c2(id='h.qf560udhgyln')
  span.c5 About the Role
p.c8
  span.c0
    | As one of our first engineering hires, you will be instrumental in building the core intelligence of our platform. You won&apos;t just be using off-the-shelf APIs; you will be building our own proprietary models from the ground up. This role is for the engineer who is obsessed with the frontier of AI research but is driven to apply it, ship it, and solve real-world problems. You will own the end-to-end lifecycle of our models, from data curation and fine-tuning to novel optimization techniques that make our systems incredibly efficient.
h3.c2(id='h.qxo4zde76s3a')
  span.c5 What You&apos;ll Do
ul.c7.lst-kix_17xl2evmkbjg-0.start
  li.c1.li-bullet-0
    span.c0
      | Build Our Core Engine: Lead the fine-tuning of state-of-the-art open-source foundation models (Llama or GPT-OSS) &nbsp;for a highly specialized and structured generative task that is core to our IP.
  li.c1.li-bullet-0
    span.c0
      | Optimize for Performance: Research and implement advanced post-training techniques, such as quantization and pruning, to create lean, high-performance models that can be deployed cost-effectively on our own infrastructure.
  li.c1.li-bullet-0
    span.c0
      | Drive Systematic Experimentation: Design and execute rigorous experiments to systematically debug and improve model behavior, establishing robust evaluation metrics and pipelines to measure performance on accuracy, speed, and cost.
  li.c1.li-bullet-0
    span.c0
      | Own the MLOps Lifecycle: Build and maintain the infrastructure for model training, versioning, and deployment, turning promising research prototypes into reliable, production-ready systems.
h3.c2(id='h.c93330ra84ys')
  span.c5 Ideal Background
ul.c7.lst-kix_818oaeavfnqw-0.start
  li.c1.li-bullet-0
    span.c0
      | You have a proven track record of turning research concepts into robust, efficient software. Years of experience are less important than the tangible systems you&apos;ve built.
  li.c1.li-bullet-0
    span.c0
      | You have significant, hands-on experience with fine-tuning large language models. You have strong intuition for data curation, training dynamics, and navigating the complexities of adapting a generalist model to a specific domain.
  li.c1.li-bullet-0
    span.c0
      | You move with urgency. You are skilled at rapid prototyping but also have the discipline to transform those prototypes into reliable, scalable systems. You thrive in an environment where cycles are measured in days, not months.
  li.c1.li-bullet-0
    span.c0
      | You are obsessed with the frontier of AI research but are ruthlessly focused on immediate, practical applications. You enjoy taking ambiguous problems, proposing solutions, and driving them to completion.
  li.c1.li-bullet-0
    span.c0
      | Strong proficiency in Python and modern ML frameworks (e.g., PyTorch or JAX). You have deep experience with the NVIDIA GPU stack and are proficient in writing and optimizing code using CUDA to maximize performance for model training and inference. You write clean, tested, and maintainable code.
h3.c2(id='h.88r0h0gfgk86')
  span.c5 Bonus Points
ul.c7.lst-kix_h27acp9hc9hw-0.start
  li.c1.li-bullet-0
    span.c0 Prior experience as a founder or founding engineer at a tech startup.
  li.c1.li-bullet-0
    span.c0 Published research at top-tier ML venues (NeurIPS, ICML, etc.).
  li.c1.li-bullet-0
    span.c0 Experience in code generation or building systems for software developers.
  li.c1.li-bullet-0
    span.c0
      | Direct experience with model compression and optimization techniques (quantization, distillation, pruning).
h3.c2(id='h.4av36od6lowo')
  span.c5 Sound like you?
p.c8
  span.c0
    | This is an opportunity to do the most meaningful work of your career. You will tackle a foundational problem in AI, build a core technology from the ground up, and help define the future of software creation.
p.c8
  span.c6 To Apply:
p.c8
  span.c4
    | Please submit your resume to jobs@create-flow.ai and a brief note explaining why you are excited about solving the problem of AI reliability. We receive a high volume of generic applications; we are looking for those who genuinely care about our mission.
p.c11
  span.c0
